{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Specification Compliance Calculation Example\n",
    "\n",
    "This example demonstrates a basic compliance calculations for various specs inside products. It utilizes the **TestMonitor Service** to load the measurements for specs inside the product, the **Spec Service** to update the specs with compliance metrics, and the **File Service** to upload the generated Analysis report.\n",
    "\n",
    "### How to use this notebook\n",
    "\n",
    "1. Upload the specs to the product.\n",
    "1. Upload the measurement data file to the product.\n",
    "1. Run the BDC extraction notebook on the measurement data file.\n",
    "1. Select one or more specs, click Analyze button in the tool bar, select this notebook and click Analyze.\n",
    "\n",
    "### About the notebook\n",
    "\n",
    "1. The notebook queries the parametric specs from the product.\n",
    "1. For each of the parametric spec in the product, the valid measurement data is stored as an array.\n",
    "1. Min, Max, Mean, Median, Standard deviation, Cp, Cpk and Health compliance is calculated for each spec.\n",
    "1. Compliance selected specs will be updated as custom properties for respective specs and the compliance report is generated and uploaded to the product.\n",
    "\n",
    "### Rules for condition mapping\n",
    "\n",
    "1. If spec condition does not have unit, step condition has unit - it will not be considered for\n",
    "   mapping.\n",
    "1. If spec condition has unit and step condition does not have unit - it will be considered for\n",
    "   mapping. Condition value will be assigned directly.\n",
    "1. If spec condition does not have unit, step condition does not have unit - it will be considered\n",
    "   for mapping. Condition value will be assigned directly without any unit conversion.\n",
    "1. If spec condition and step condition both have the same unit - it will be considered for mapping.\n",
    "   Condition value will be assigned directly.\n",
    "1. If spec condition and step condition have different units with same base unit - it will be\n",
    "   considered for mapping. Condition value will be converted to spec condition unit and assigned.\n",
    "1. If spec condition and step condition have different units with different base unit - it will not\n",
    "   be considered for mapping.\n",
    "\n",
    "### Rules for step condition within spec condition\n",
    "\n",
    "1. If the step condition value is not present - it can be considered as within range.\n",
    "1. If the step condition value is present and within spec condition range and/or discrete array - it\n",
    "   can be considered as within range.\n",
    "\n",
    "### Rules for measurement data\n",
    "\n",
    "1. If spec and measurement data does not have unit - the measurement data will be considered for\n",
    "   compliance calculation.\n",
    "1. If spec has unit and measurement data does not have unit or spec does not have unit and\n",
    "   measurement data has unit - it will not be considered for compliance calculation.\n",
    "1. If spec and measurement data has different base unit - it will not be considered for compliance\n",
    "   calculation.\n",
    "1. If spec and measurement data has unit - the measurement data will be converted from base unit to \n",
    "   the spec unit (Assuming measurement data will be stored in base unit. Ex:BDC extraction notebook\n",
    "   will store the measurement data in base unit).\n",
    "1. If measurement data for a row is empty - it will not be considered for compliance calculation.\n",
    "1. If measurement data for a row is not convertible to Decimal - it will not be considered for\n",
    "   compliance calculation.\n",
    "\n",
    "### Rules for spec health calculation\n",
    "\n",
    "1. If spec min value is null and spec max value is not null, spec health will be 'Pass' if max\n",
    "   compliance <= spec max, else spec health will be 'Fail'.\n",
    "1. If spec max value is null and spec min value is not null, spec health will be 'Pass' if min\n",
    "   compliance >= spec min, else spec health will be 'Fail'.\n",
    "1. If spec min and spec max value is null, spec health will be 'Pass'.\n",
    "1. If both spec min and spec max value are not null, spec health will be 'Pass' when min and max\n",
    "   compliance is within spec min and spec max, else spec health will be 'Fail'.\n",
    "\n",
    "**Note: Any other cases not mentioned above may/may not work. The notebook is designed to work**\n",
    "**only with the above mentioned cases**\n",
    "\n",
    "### Known cases where notebook does not work\n",
    "1. If a spec has two or more conditions with the same name but different units, the compliance might\n",
    "   not be calculated properly, only one of these conditions will be displayed in the compliance\n",
    "   excel report and the condition data might not match with the actual spec condition. (Ex:\n",
    "   Spec01 has two condition entries vcc(V), Vcc(I))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Import Python Modules for executing the notebook. The requests, aiohttp, systemlink and json library are used for communicating with various SystemLink Enterprise's endpoints. Pandas is used for building and handling dataframe. Scrapbook is used for running notebooks and recording data for the SystemLink Notebook Execution Service.\n",
    "\n",
    "The SYSTEMLINK_API_KEY environment variable specifies an API key created for the user executinge this notebook, which provides Role Based Access Control to the various SystemLink APIs called by this notebook. The API key will expire after 24 hours.\n",
    "The SYSTEMLINK_HTTP_URI environment variable gives the base URL to the SystemLink instance executing this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from decimal import Decimal, InvalidOperation\n",
    "from http import HTTPStatus\n",
    "from typing import Any, Callable, Dict, List, Tuple\n",
    "\n",
    "import aiohttp\n",
    "import backoff\n",
    "import pandas as pd\n",
    "import requests\n",
    "import scrapbook as sb\n",
    "from ni_unit_converter import convert_from_base_unit, convert_to_base_unit\n",
    "from requests import Response\n",
    "from requests.exceptions import HTTPError\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "from systemlink.clients.nitestmonitor import StepsApi\n",
    "from systemlink.clients.nitestmonitor.models import StepsAdvancedQuery\n",
    "\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "api_key = os.getenv(\"SYSTEMLINK_API_KEY\")\n",
    "systemlink_uri = os.getenv(\"SYSTEMLINK_HTTP_URI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Parameters\n",
    "\n",
    "These are the parameters that the notebook expects to be passed in by SystemLink. For notebooks designed to be triggered by pressing the 'Analyze' button in SystemLink Specs grid inside product details page, they must tag the cell with 'parameters' and at minimum specify the following in the cell metadata using the JupyterLab Property Inspector (double gear icon):\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"papermill\": {\n",
    "    \"parameters\": {\n",
    "      \"spec_ids\": [],\n",
    "      \"product_id\": \"\"\n",
    "    }\n",
    "  },\n",
    "  \"systemlink\": {\n",
    "    \"namespaces\": [],\n",
    "    \"parameters\": [\n",
    "      {\n",
    "        \"display_name\": \"spec_ids\",\n",
    "        \"id\": \"spec_ids\",\n",
    "        \"type\": \"string[]\"\n",
    "      },\n",
    "      {\n",
    "        \"display_name\": \"product_id\",\n",
    "        \"id\": \"product_id\",\n",
    "        \"type\": \"string\"\n",
    "      }\n",
    "    ],\n",
    "    \"version\": 2\n",
    "  },\n",
    "  \"tags\": [\"parameters\"]\n",
    "}\n",
    "```\n",
    "\n",
    "For more information on how parameterization works, review the [papermill documentation](https://papermill.readthedocs.io/en/latest/usage-parameterize.html#how-parameters-work).\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "parameters": {
      "product_id": "",
      "spec_ids": []
     }
    },
    "systemlink": {
     "namespaces": [],
     "parameters": [
      {
       "display_name": "spec_ids",
       "id": "spec_ids",
       "type": "string[]"
      },
      {
       "display_name": "product_id",
       "id": "product_id",
       "type": "string"
      }
     ],
     "version": 2
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "spec_ids = []\n",
    "product_id = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTTP Status Codes and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_HTTP_RETRIES = 6\n",
    "TIMEOUT_IN_SECONDS = 60\n",
    "VERIFY_SSL_CERTIFICATE = False\n",
    "QUERY_SPECS_TAKE_COUNT = 1000\n",
    "QUERY_STEPS_TAKE_COUNT = 1000\n",
    "HTTP_RETRY_CODES = [\n",
    "    HTTPStatus.TOO_MANY_REQUESTS,\n",
    "    HTTPStatus.INTERNAL_SERVER_ERROR,\n",
    "    HTTPStatus.BAD_GATEWAY,\n",
    "    HTTPStatus.SERVICE_UNAVAILABLE,\n",
    "    HTTPStatus.GATEWAY_TIMEOUT\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API URL's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApiUrls:\n",
    "    QUERY_PRODUCTS_URL = f\"{systemlink_uri}/nitestmonitor/v2/query-products\"\n",
    "    UPDATE_PRODUCT_URL = f\"{systemlink_uri}/nitestmonitor/v2/update-products\"\n",
    "    QUERY_SPECS_URL = f\"{systemlink_uri}/nispec/v1/query-specs\"\n",
    "    UPDATE_SPECS_URL = f\"{systemlink_uri}/nispec/v1/update-specs\"\n",
    "    QUERY_STEPS_URL = f\"{systemlink_uri}/nitestmonitor/v2/query-steps\"\n",
    "    GET_PRODUCT_URL = f\"{systemlink_uri}/nitestmonitor/v2/products\"\n",
    "    GET_FILE_PROPERTIES_URL = f\"{systemlink_uri}/nifile/v1/service-groups/Default/files\"\n",
    "    UPLOAD_FILE_URL = f\"{systemlink_uri}/nifile/v1/service-groups/Default/upload-files\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Utility functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@backoff.on_exception(\n",
    "    backoff.expo,\n",
    "    HTTPError,\n",
    "    max_tries=MAX_HTTP_RETRIES,\n",
    "    giveup=lambda e: e.response.status_code not in HTTP_RETRY_CODES,\n",
    ")\n",
    "def retry_request(callable_function: Callable) -> Response:\n",
    "    \"\"\"Run the callable function and raise for status\n",
    "\n",
    "    Args:\n",
    "        callable_function (Callable): Callable request function\n",
    "\n",
    "    Returns:\n",
    "        Response: Callable function response\n",
    "    \"\"\"\n",
    "    response = callable_function()\n",
    "    response.raise_for_status()\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def create_get_request(url: str, headers: Dict = None) -> Response:\n",
    "    \"\"\"Get request\n",
    "\n",
    "    Args:\n",
    "        url (str): API URL\n",
    "        headers (Dict, optional): API request headers. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        Response: Get request response\n",
    "    \"\"\"\n",
    "    if not headers:\n",
    "        headers = {}\n",
    "    default_headers = {\"x-ni-api-key\": api_key}\n",
    "    headers = {**default_headers, **headers}\n",
    "\n",
    "    return retry_request(\n",
    "        lambda: requests.get(\n",
    "            url, headers=headers, verify=VERIFY_SSL_CERTIFICATE, timeout=TIMEOUT_IN_SECONDS\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def create_post_request(url: str, body, headers: Dict = None) -> Response:\n",
    "    \"\"\"Post request\n",
    "\n",
    "    Args:\n",
    "        url (str): API URL\n",
    "        body (_type_): Request body\n",
    "        headers (Dict, optional): API request headers. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        Response: Post request response\n",
    "    \"\"\"\n",
    "    if not headers:\n",
    "        headers = {}\n",
    "    default_headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"x-ni-api-key\": api_key,\n",
    "    }\n",
    "    headers = {**default_headers, **headers}\n",
    "\n",
    "    return retry_request(\n",
    "        lambda: requests.post(\n",
    "            url,\n",
    "            json=body,\n",
    "            headers=headers,\n",
    "            verify=VERIFY_SSL_CERTIFICATE,\n",
    "            timeout=TIMEOUT_IN_SECONDS,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def upload_file_request(url: str, file: Any, headers: Dict = None) -> Response:\n",
    "    \"\"\"Upload file post request\n",
    "\n",
    "    Args:\n",
    "        url (str): API URL\n",
    "        file (Any): File content\n",
    "        headers (Dict, optional): API request headers. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        Response: Upload file request response\n",
    "    \"\"\"\n",
    "    if not headers:\n",
    "        headers = {}\n",
    "    default_headers = {\"accept\": \"application/json\", \"x-ni-api-key\": api_key}\n",
    "    headers = {**default_headers, **headers}\n",
    "\n",
    "    return retry_request(\n",
    "        lambda: requests.post(\n",
    "            url, files=file, headers=headers, verify=False, timeout=TIMEOUT_IN_SECONDS\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApiBody:\n",
    "    PRODUCT_IDS = \"productIds\"\n",
    "    TAKE = \"take\"\n",
    "    TYPE = \"type\"\n",
    "    PARAMETRIC = \"PARAMETRIC\"\n",
    "    SPECS = \"specs\"\n",
    "    CONTINUATION_TOKEN = \"continuationToken\"\n",
    "    JSON = \"JSON\"\n",
    "    RESPONSE_FORMAT = \"responseFormat\"\n",
    "    SPEC_ID = \"SpecID\"\n",
    "    STEP_ID = \"STEP_ID\"\n",
    "    FILTER = \"filter\"\n",
    "    RESULT_FILTER = \"resultFilter\"\n",
    "    ORDER_BY = \"orderBy\"\n",
    "    FILE_IDS = \"fileIds\"\n",
    "    PART_NUMBER = \"partNumber\"\n",
    "    DATA = \"data\"\n",
    "    PARAMETERS = \"parameters\"\n",
    "    ANY = \"Any\"\n",
    "    IT = \"it\"\n",
    "    PROJECTION = \"projection\"\n",
    "    PRODUCTS = \"products\"\n",
    "    REPLACE = \"replace\"\n",
    "    FALSE = \"false\"\n",
    "    WORKSPACE = \"workspace\"\n",
    "\n",
    "\n",
    "class ApiResponse:\n",
    "    TYPE = \"type\"\n",
    "    ID = \"id\"\n",
    "    SPEC_ID = \"specId\"\n",
    "    SPECS = \"specs\"\n",
    "    STEPS = \"steps\"\n",
    "    PARAMETRIC = \"PARAMETRIC\"\n",
    "    PRODUCTS = \"products\"\n",
    "    AVAILABLE_FILES = \"availableFiles\"\n",
    "    WORKSPACE = \"workspace\"\n",
    "    FILE_IDS = \"fileIds\"\n",
    "    UPDATED_AT = \"updatedAt\"\n",
    "    URI = \"uri\"\n",
    "    EMPTY = \"Empty\"\n",
    "\n",
    "\n",
    "class Projection:\n",
    "    INPUTS = \"INPUTS\"\n",
    "    DATA = \"DATA\"\n",
    "    STEP_ID = \"STEP_ID\"\n",
    "\n",
    "\n",
    "class Spec:\n",
    "    SPECID = \"specId\"\n",
    "    CATEGORY = \"category\"\n",
    "    BLOCK = \"block\"\n",
    "    SYMBOL = \"symbol\"\n",
    "    LIMIT = \"limit\"\n",
    "    CONDITIONS = \"conditions\"\n",
    "    NAME = \"name\"\n",
    "    VALUE = \"value\"\n",
    "    RANGE = \"range\"\n",
    "    MIN = \"min\"\n",
    "    MAX = \"max\"\n",
    "    STEP = \"step\"\n",
    "    TYPICAL = \"typical\"\n",
    "    UNIT = \"unit\"\n",
    "    DISCRETE = \"discrete\"\n",
    "    PROPERTIES = \"properties\"\n",
    "\n",
    "\n",
    "class Step:\n",
    "    INPUTS = \"inputs\"\n",
    "    NAME = \"name\"\n",
    "    VALUE = \"value\"\n",
    "    DATA = \"data\"\n",
    "    PARAMETERS = \"parameters\"\n",
    "    MEASUREMENT = \"measurement\"\n",
    "    SPEC_ID = \"SpecID\"\n",
    "    UNITS = \"units\"\n",
    "\n",
    "\n",
    "class DataframeHeaders:\n",
    "    SPEC_DETAILS = \"Spec Details\"\n",
    "    SPEC_ID = \"SpecID\"\n",
    "    CATEGORY = \"Category\"\n",
    "    BLOCK = \"Block\"\n",
    "    SYMBOL = \"Symbol\"\n",
    "    NAME = \"Name\"\n",
    "    MIN = \"Min\"\n",
    "    TYPICAL = \"Typical\"\n",
    "    MAX = \"Max\"\n",
    "    UNIT = \"Unit\"\n",
    "    DISCRETE = \"Discrete\"\n",
    "    STEP = \"Step\"\n",
    "    CONDITION = \"Condition\"\n",
    "    COMPLIANCE = \"Compliance\"\n",
    "    CP = \"Cp\"\n",
    "    CPK = \"Cpk\"\n",
    "    STANDARD_DEVIATION = \"Standard Deviation\"\n",
    "\n",
    "\n",
    "class ComplianceParameters:\n",
    "    MIN = \"Min\"\n",
    "    MAX = \"Max\"\n",
    "    MEAN = \"Mean\"\n",
    "    MEDIAN = \"Median\"\n",
    "    HEALTH = \"Health\"\n",
    "    CP = \"Cp\"\n",
    "    CPK = \"Cpk\"\n",
    "    STANDARD_DEVIATION = \"Standard Deviation\"\n",
    "\n",
    "\n",
    "class SpecComplianceProperties:\n",
    "    MIN = \"Compliance Min\"\n",
    "    MAX = \"Compliance Max\"\n",
    "    MEAN = \"Compliance Mean\"\n",
    "    MEDIAN = \"Compliance Median\"\n",
    "    HEALTH = \"Compliance Health\"\n",
    "    CP = \"Compliance Cp\"\n",
    "    CPK = \"Compliance Cpk\"\n",
    "    STANDARD_DEVIATION = \"Compliance Standard Deviation\"\n",
    "\n",
    "\n",
    "class SpecHealth:\n",
    "    PASS = \"Pass\"\n",
    "    FAIL = \"Fail\"\n",
    "    INF = \"inf\"\n",
    "    NEGATIVE_INF = \"-inf\"\n",
    "    NAN = \"nan\"\n",
    "\n",
    "MAX_SPECS_PER_UPDATE_REQUEST = 100\n",
    "EXCEL_FILE_NAME = \"Spec_Compliance.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErrorMessages:\n",
    "    MISMATCHING_BASE_UNITS = \"Input and output units are having different base unit\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Workspace ID of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace_id(file_id: str) -> str:\n",
    "    \"\"\"Retrieve the associated workspace ID for the given file ID\n",
    "\n",
    "    Args:\n",
    "        FILE_ID (str): File ID\n",
    "\n",
    "    Returns:\n",
    "        str: Workspace ID\n",
    "    \"\"\"\n",
    "    get_file_properties_url = f\"{ApiUrls.GET_FILE_PROPERTIES_URL}?id={file_id}\"\n",
    "    resp_json = create_get_request(get_file_properties_url)\n",
    "    resp = resp_json.json()\n",
    "    workspace_id = resp[ApiResponse.AVAILABLE_FILES][0][ApiResponse.WORKSPACE]\n",
    "\n",
    "    return str(workspace_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Product Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_information(product_id: str) -> Response:\n",
    "    \"\"\"Get the product response\n",
    "\n",
    "    Args:\n",
    "        product_id (str): Product ID\n",
    "\n",
    "    Returns:\n",
    "        Response: Product response\n",
    "    \"\"\"\n",
    "    headers = {\"accept\": \"application/json\", \"Content-Type\": \"application/json\"}\n",
    "    response = create_get_request(f\"{ApiUrls.GET_PRODUCT_URL}/{product_id}\", headers)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_information = get_product_information(product_id).json()\n",
    "part_number = product_information[ApiBody.PART_NUMBER]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __batch_query_request(url: str, body: Dict[str, Any], response_key: str) -> List:\n",
    "    \"\"\"Query request in batches, accumulate and return the data\n",
    "\n",
    "    Args:\n",
    "        url (str): URL for query request\n",
    "        body (Dict[str, Any]): Body of the query request\n",
    "        response_key (str): Key to retrieve data from the response\n",
    "\n",
    "    Returns:\n",
    "        List: List of data retrieved from the response\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    response = create_post_request(url, body)\n",
    "    response = response.json()\n",
    "    if response is not None and response[response_key] is not None:\n",
    "        data.extend(response[response_key])\n",
    "    while response[ApiBody.CONTINUATION_TOKEN]:\n",
    "        body[ApiBody.CONTINUATION_TOKEN] = response[ApiBody.CONTINUATION_TOKEN]\n",
    "        response = create_post_request(url, body)\n",
    "        response = response.json()\n",
    "        if response is not None and response[response_key] is not None:\n",
    "            data.extend(response[response_key])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def __generate_spec_ids_filter() -> str:\n",
    "    filter = ''\n",
    "    for index, spec_id in enumerate(spec_ids):\n",
    "        filter += f'specId == \\\"{spec_id}\\\"'\n",
    "        if index < len(spec_ids) - 1:\n",
    "            filter += \" || \"\n",
    "    return filter\n",
    "    \n",
    "def query_parametric_specs(product_id: str) -> List:\n",
    "    \"\"\"\n",
    "    Query Parametric specs in the product\n",
    "\n",
    "    Args:\n",
    "        product_id (str): Product ID\n",
    "\n",
    "    Returns:\n",
    "        List: Parametric specs in the product\n",
    "    \"\"\"\n",
    "    spec_ids_filter = __generate_spec_ids_filter()\n",
    "    body = {\n",
    "        ApiBody.PRODUCT_IDS: [product_id],\n",
    "        ApiBody.FILTER: f\"(({spec_ids_filter}) && ({ApiBody.TYPE} == \\\"{ApiBody.PARAMETRIC}\\\"))\",\n",
    "        ApiBody.TAKE: QUERY_SPECS_TAKE_COUNT\n",
    "    }\n",
    "    specs = __batch_query_request(ApiUrls.QUERY_SPECS_URL, body, ApiResponse.SPECS)\n",
    "\n",
    "    return specs\n",
    "\n",
    "def update_specs(updated_specs: List) -> Response:\n",
    "    body = {\n",
    "        ApiBody.SPECS: updated_specs\n",
    "    }\n",
    "    return create_post_request(ApiUrls.UPDATE_SPECS_URL, body)\n",
    "\n",
    "async def __query_steps(request: StepsAdvancedQuery) -> aiohttp.ClientResponse:\n",
    "    \"\"\"Query steps\n",
    "\n",
    "    Args:\n",
    "        request (StepsAdvancedQuery): Request body for query steps api\n",
    "\n",
    "    Returns:\n",
    "        aiohttp.ClientResponse: Client response\n",
    "    \"\"\"    \n",
    "    return await StepsApi().query_steps_v2(post_body=request, _preload_content=False)\n",
    "\n",
    "\n",
    "async def __batch_query_steps(part_number: str, spec_id: str) -> List:\n",
    "    \"\"\"Batch query steps\n",
    "\n",
    "    Args:\n",
    "        part_number (str): Part number\n",
    "        spec_id (str): Specification ID\n",
    "\n",
    "    Raises:\n",
    "        Exception: Raises exception when there is a client response error\n",
    "\n",
    "    Returns:\n",
    "        List: Steps which contains the measurement data for the given specification ID\n",
    "    \"\"\"    \n",
    "    data = []\n",
    "    request = StepsAdvancedQuery(\n",
    "        filter=f'({ApiBody.DATA}.{ApiBody.PARAMETERS}.{ApiBody.ANY}({ApiBody.IT}[\"{ApiBody.SPEC_ID}\"] = \"{spec_id}\"))',\n",
    "        result_filter=f'({ApiBody.PART_NUMBER} == \"{part_number}\")',\n",
    "        take=QUERY_STEPS_TAKE_COUNT,\n",
    "        projection=[Projection.DATA, Projection.INPUTS],\n",
    "        response_format= ApiBody.JSON,\n",
    "    )\n",
    "    try:\n",
    "        response = await __query_steps(request)\n",
    "        response = await response.json()\n",
    "        if response is not None and response[ApiResponse.STEPS] is not None:\n",
    "            data.extend(response[ApiResponse.STEPS])\n",
    "        while response[ApiBody.CONTINUATION_TOKEN]:\n",
    "            request = StepsAdvancedQuery(\n",
    "                filter=f'({ApiBody.DATA}.{ApiBody.PARAMETERS}.{ApiBody.ANY}({ApiBody.IT}[\"{ApiBody.SPEC_ID}\"] = \"{spec_id}\"))',\n",
    "                result_filter=f'({ApiBody.PART_NUMBER} == \"{part_number}\")',\n",
    "                take=QUERY_STEPS_TAKE_COUNT,\n",
    "                projection=[Projection.DATA, Projection.INPUTS],\n",
    "                response_format= ApiBody.JSON,\n",
    "                continuation_token=response[ApiBody.CONTINUATION_TOKEN],\n",
    "            )\n",
    "            response = await __query_steps(request)\n",
    "            response = await response.json()\n",
    "            if response is not None and response[ApiResponse.STEPS] is not None:\n",
    "                data.extend(response[ApiResponse.STEPS])\n",
    "    except aiohttp.ClientResponseError:\n",
    "        raise Exception\n",
    "    return data\n",
    "\n",
    "\n",
    "async def query_steps(part_number: str, spec_id: str) -> List:\n",
    "    \"\"\"\n",
    "    Query steps\n",
    "\n",
    "    Args:\n",
    "        part_number (str): Part number\n",
    "        spec_id (str): Specification ID\n",
    "\n",
    "    Returns:\n",
    "        List: Steps which contains the measurement data for the given specification ID\n",
    "    \"\"\"\n",
    "    steps = await __batch_query_steps(part_number, spec_id)\n",
    "\n",
    "    return steps\n",
    "\n",
    "\n",
    "def __convert_to_decimal(value: str) -> Decimal | None:\n",
    "    \"\"\"Converts the value to decimal\n",
    "\n",
    "    Args:\n",
    "        value (str): value in string format\n",
    "\n",
    "    Returns:\n",
    "        Decimal | None: returns the converted value\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return Decimal(value)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def __convert_to_bool(value: str) -> bool | None:\n",
    "    \"\"\"Converts the value to boolean\n",
    "\n",
    "    Args:\n",
    "        value (str): value in string format\n",
    "\n",
    "    Returns:\n",
    "        bool | None: returns the converted value\n",
    "    \"\"\"\n",
    "    if value in [\"True\", \"true\"]:\n",
    "        return True\n",
    "    if value in [\"False\", \"false\"]:\n",
    "        return False\n",
    "    return None\n",
    "\n",
    "\n",
    "def __convert_to_datatype(value: str) -> bool | Decimal | str:\n",
    "    \"\"\"Convert the given string to any one of these types (decimal, bool)\n",
    "\n",
    "    Args:\n",
    "        value (str): String value\n",
    "\n",
    "    Returns:\n",
    "        bool | Decimal | str: returns the converted value\n",
    "    \"\"\"\n",
    "    bool_value = __convert_to_bool(value=value)\n",
    "    if bool_value is not None:\n",
    "        return bool_value\n",
    "\n",
    "    decimal_value = __convert_to_decimal(value=value)\n",
    "    if decimal_value is not None:\n",
    "        return decimal_value\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "def get_spec_condition(spec: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Get the specification conditions as a dictionary\n",
    "\n",
    "    Args:\n",
    "        spec (Dict): Specification data\n",
    "\n",
    "    Returns:\n",
    "        Dict: Specification Conditions as a dict\n",
    "    \"\"\"\n",
    "    spec_condition = {}\n",
    "\n",
    "    for condition in spec[Spec.CONDITIONS]:\n",
    "        spec_condition[condition[Spec.NAME]] = condition[Spec.VALUE]\n",
    "\n",
    "    return spec_condition\n",
    "\n",
    "\n",
    "def extract_condition_name_and_unit(condition_string: str) -> Tuple[str, str | None]:\n",
    "    \"\"\"\n",
    "    Extract the condition name and unit seperately from the condition string\n",
    "\n",
    "    Args:\n",
    "        condition_string (str): Condition string which contains the name and unit\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, str | None]: Condition name, Condition Unit\n",
    "    \"\"\"\n",
    "    pattern = r'^(.*?)\\((.*?)\\)$'\n",
    "    match = re.match(pattern, condition_string)\n",
    "    if match:\n",
    "        condition_name = match.group(1).strip()\n",
    "        condition_unit = match.group(2).strip()\n",
    "\n",
    "        return condition_name, condition_unit\n",
    "\n",
    "    return condition_string.strip(), None\n",
    "\n",
    "\n",
    "def is_different_base_unit(input_unit: str, output_unit: str) -> bool:\n",
    "    \"\"\"Check if both the units have different base unit\n",
    "\n",
    "    Args:\n",
    "        input_unit (str): Input unit\n",
    "        output_unit (str): Output unit\n",
    "\n",
    "    Returns:\n",
    "        bool: Returns true if both the units have different base unit, else returns false\n",
    "    \"\"\"\n",
    "    input_base_unit = convert_to_base_unit(input_unit, 1).base_unit\n",
    "    output_base_unit = convert_to_base_unit(output_unit, 1).base_unit\n",
    "\n",
    "    if input_base_unit != output_base_unit:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def convert_unit(input_unit: str, output_unit: str, value: str) -> Decimal:\n",
    "    \"\"\"\n",
    "    Converts the value from input unit to output unit\n",
    "\n",
    "    Args:\n",
    "        input_unit (str): Input unit\n",
    "        output_unit (str): Ouput unit\n",
    "        value (str): Value to be converted\n",
    "\n",
    "    Raises:\n",
    "        Exception: Input and output units are having different base unit\n",
    "\n",
    "    Returns:\n",
    "        Decimal: Value converted from input unit to output unit\n",
    "    \"\"\"\n",
    "    if is_different_base_unit(input_unit, output_unit):\n",
    "        raise Exception(ErrorMessages.MISMATCHING_BASE_UNITS)\n",
    "    output_value = convert_to_base_unit(input_unit, value).converted_value\n",
    "    output_value = convert_from_base_unit(output_unit, output_value)\n",
    "\n",
    "    return output_value\n",
    "\n",
    "\n",
    "def get_step_condition_matching_the_spec_condition(step: Dict, spec_condition: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Returns the step conditions matching the spec conditions as a dictionary\n",
    "\n",
    "    Args:\n",
    "        step (Dict): Step data\n",
    "        spec_condition (Dict): Spec Conditions dictionary\n",
    "\n",
    "    Returns:\n",
    "        Dict: Step conditions matching the spec conditions\n",
    "    \"\"\"\n",
    "    step_condition = {}\n",
    "\n",
    "    if Step.INPUTS not in step:\n",
    "        return step_condition\n",
    "    for step_input in step[Step.INPUTS]:\n",
    "        step_condition_name, step_condition_unit = extract_condition_name_and_unit(\n",
    "            step_input[Step.NAME]\n",
    "        )\n",
    "\n",
    "        if step_condition_name not in spec_condition:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            spec_condition_unit = spec_condition[step_condition_name][Spec.UNIT]\n",
    "            if spec_condition_unit is None and step_condition_unit:\n",
    "                continue\n",
    "        except KeyError:\n",
    "            spec_condition_unit = None\n",
    "            if step_condition_unit:\n",
    "                continue\n",
    "\n",
    "        if (step_condition_unit == spec_condition_unit) or (\n",
    "            spec_condition_unit and not step_condition_unit\n",
    "        ):\n",
    "            try:\n",
    "                step_condition[step_condition_name] = (\n",
    "                    Decimal(str(step_input[Step.VALUE])) if Step.VALUE in step_input else ''\n",
    "                )\n",
    "            except InvalidOperation:\n",
    "                step_condition[step_condition_name] = step_input[Step.VALUE]\n",
    "        else:\n",
    "            if is_different_base_unit(step_condition_unit, spec_condition_unit):\n",
    "                continue\n",
    "            if Step.VALUE not in step_input or (\n",
    "                Step.VALUE in step_input and step_input[Step.VALUE] == str()\n",
    "            ):\n",
    "                step_condition[step_condition_name] = str()\n",
    "            else:\n",
    "                try:\n",
    "                    step_condition_value = convert_unit(\n",
    "                        step_condition_unit, spec_condition_unit, str(step_input[Step.VALUE])\n",
    "                    )\n",
    "                    step_condition[step_condition_name] = step_condition_value\n",
    "                except (ValueError, InvalidOperation):\n",
    "                    step_condition[step_condition_name] = step_input[Step.VALUE]\n",
    "\n",
    "    return step_condition\n",
    "\n",
    "\n",
    "def check_step_condition_within_spec_condition_range(\n",
    "    spec_condition: Dict,\n",
    "    condition_name: str,\n",
    "    condition_value: Decimal\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Checks if the step condition value is within the spec condition range\n",
    "\n",
    "    Args:\n",
    "        spec_condition (Dict): Specification condition\n",
    "        condition_name (str): Condition name\n",
    "        condition_value (Decimal): Condition value\n",
    "\n",
    "    Returns:\n",
    "        bool: Returns true if step condition is within spec condition range , else returns false\n",
    "    \"\"\"\n",
    "    if Spec.RANGE in spec_condition[condition_name] and spec_condition[condition_name][Spec.RANGE]:\n",
    "        for spec_condition_range in spec_condition[condition_name][Spec.RANGE]:\n",
    "            min_limit = __convert_to_decimal(str(spec_condition_range[Spec.MIN]))\n",
    "            max_limit = __convert_to_decimal(str(spec_condition_range[Spec.MAX]))\n",
    "            if (min_limit is None or condition_value >= min_limit) and (\n",
    "                max_limit is None or condition_value <= max_limit\n",
    "            ):\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def check_step_condition_within_spec_condition_discrete_array(\n",
    "    spec_condition: Dict,\n",
    "    condition_name: str,\n",
    "    condition_value: Decimal | str\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Check if the step condition value is within the spec condition discrete array\n",
    "\n",
    "    Args:\n",
    "        spec_condition (Dict): Specification condition\n",
    "        condition_name (str): Condition name\n",
    "        condition_value (Decimal | str): Condition value\n",
    "\n",
    "    Returns:\n",
    "        bool: Returns true if step condition value is within the spec condition discrete array else returns false\n",
    "    \"\"\"\n",
    "    if Spec.DISCRETE in spec_condition[condition_name]:\n",
    "        discrete_values = spec_condition[condition_name][Spec.DISCRETE]\n",
    "        converted_discrete_values = []\n",
    "        for discrete_value in discrete_values:\n",
    "            converted_discrete_values.append(__convert_to_datatype(str(discrete_value)))\n",
    "        if condition_value in converted_discrete_values:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def check_step_condition_within_spec_condition(spec_condition: Dict, step_condition: Dict) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the step condition value is within the spec condition\n",
    "\n",
    "    Condition mapping rules:\n",
    "    1. If condition value in measurement data is empty, it is considered as within bounds\n",
    "    2. If condition value in measurement data is within bounds of either range or discrete array of spec condition, it is considered as within bounds\n",
    "\n",
    "    Args:\n",
    "        spec_condition (Dict): Specification condition\n",
    "        step_condition (Dict): Step condition\n",
    "\n",
    "    Returns:\n",
    "        bool: Returns true if  step condition is within the spec condition, else returns false\n",
    "    \"\"\"\n",
    "    condition_within_range = True\n",
    "\n",
    "    for condition_name, condition_value in step_condition.items():\n",
    "        try:\n",
    "            condition_value = Decimal(str(condition_value))\n",
    "        except InvalidOperation:\n",
    "            pass\n",
    "\n",
    "        if not condition_value and isinstance(condition_value, str):\n",
    "            continue\n",
    "\n",
    "        condition_within_range = (\n",
    "            (\n",
    "                check_step_condition_within_spec_condition_range(\n",
    "                    spec_condition, condition_name, condition_value\n",
    "                )\n",
    "                or check_step_condition_within_spec_condition_discrete_array(\n",
    "                    spec_condition, condition_name, condition_value\n",
    "                )\n",
    "            )\n",
    "            if isinstance(condition_value, Decimal)\n",
    "            else check_step_condition_within_spec_condition_discrete_array(\n",
    "                spec_condition, condition_name, condition_value\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if not condition_within_range:\n",
    "            return condition_within_range\n",
    "\n",
    "    return condition_within_range\n",
    "\n",
    "\n",
    "def fetch_measurement_data_for_spec(\n",
    "    steps: List,\n",
    "    spec_id: str,\n",
    "    spec_condition: Dict,\n",
    "    spec_unit: str | None\n",
    ") -> List:\n",
    "    \"\"\"\n",
    "    Returns a list of measurement data associated with the spec after condition mapping\n",
    "\n",
    "    Measurement data rules:\n",
    "    1. If Measurement value is empty, it is not considered for compliance\n",
    "    2. If Measurement value is not a valid number, it is not considered for compliance\n",
    "\n",
    "    Args:\n",
    "        steps (List): Steps data\n",
    "        spec_id (str): Specification ID\n",
    "        spec_condition (Dict): Specification condition\n",
    "        spec_unit (str | None): Specification unit\n",
    "\n",
    "    Returns:\n",
    "        List: Measurement data\n",
    "    \"\"\"\n",
    "    measurement_data = []\n",
    "\n",
    "    for step in steps:\n",
    "        step_condition = get_step_condition_matching_the_spec_condition(step, spec_condition)\n",
    "        if not check_step_condition_within_spec_condition(spec_condition, step_condition):\n",
    "            continue\n",
    "        if Step.DATA not in step or Step.PARAMETERS not in step[Step.DATA]:\n",
    "            continue\n",
    "        for parameter in step[Step.DATA][Step.PARAMETERS]:\n",
    "            step_unit = parameter[Step.UNITS]\n",
    "            if parameter[Step.UNITS] is str():\n",
    "                step_unit = None\n",
    "            if (spec_unit and not step_unit) or (step_unit and not spec_unit):\n",
    "                continue\n",
    "            if spec_unit and step_unit and is_different_base_unit(step_unit, spec_unit):\n",
    "                continue\n",
    "            if Step.SPEC_ID in parameter and parameter[Step.SPEC_ID] != spec_id:\n",
    "                continue\n",
    "            measurement_value = (\n",
    "                parameter[Step.MEASUREMENT] if Step.MEASUREMENT in parameter else str()\n",
    "            )\n",
    "            if measurement_value:\n",
    "                try:\n",
    "                    if not spec_unit:\n",
    "                        measurement_data.append(Decimal(str(measurement_value)))\n",
    "                    else:\n",
    "                        measurement_value = convert_from_base_unit(spec_unit, measurement_value)\n",
    "                        measurement_data.append(measurement_value)\n",
    "                except (TypeError, ValueError, InvalidOperation):\n",
    "                    continue\n",
    "\n",
    "    return measurement_data\n",
    "\n",
    "\n",
    "def calculate_compliance(measurement_data: pd.DataFrame, parameter: str) -> pd.Series:\n",
    "    \"\"\"Calculate compliance for the measurement data\n",
    "\n",
    "    Args:\n",
    "        measurement_data (pd.DataFrame): Spec measurement data\n",
    "        parameter (str): Compliance parameter\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Calculated compliance\n",
    "    \"\"\"\n",
    "    if parameter == ComplianceParameters.MIN:\n",
    "        return measurement_data.min(skipna=True)\n",
    "    if parameter == ComplianceParameters.MAX:\n",
    "        return measurement_data.max(skipna=True)\n",
    "    if parameter == ComplianceParameters.MEAN:\n",
    "        return measurement_data.mean(skipna=True)\n",
    "    if parameter == ComplianceParameters.MEDIAN:\n",
    "        return measurement_data.median(skipna=True)\n",
    "    return pd.Series()\n",
    "\n",
    "\n",
    "def get_spec_health(spec, min_compliance: str, max_compliance: str) -> str | None:\n",
    "    \"\"\"Calculate spec health based on min and max compliance\n",
    "\n",
    "    Args:\n",
    "        spec (_type_): Specification data\n",
    "        min_compliance (str): Min compliance value\n",
    "        max_compliance (str): Max compliance value\n",
    "\n",
    "    Returns:\n",
    "        str | None: Returns Pass or Fail, None if there are any errors\n",
    "    \"\"\"\n",
    "    if spec[Spec.UNIT] is not None:\n",
    "        spec_min = (\n",
    "            convert_to_base_unit(spec[Spec.UNIT], spec[Spec.LIMIT][Spec.MIN]).converted_value\n",
    "            if spec[Spec.LIMIT][Spec.MIN] is not None\n",
    "            else Decimal(SpecHealth.NEGATIVE_INF)\n",
    "        )\n",
    "        spec_max = (\n",
    "            convert_to_base_unit(spec[Spec.UNIT], spec[Spec.LIMIT][Spec.MAX]).converted_value\n",
    "            if spec[Spec.LIMIT][Spec.MAX] is not None\n",
    "            else Decimal(SpecHealth.INF)\n",
    "        )\n",
    "        min_compliance = convert_to_base_unit(spec[Spec.UNIT], min_compliance).converted_value\n",
    "        max_compliance = convert_to_base_unit(spec[Spec.UNIT], max_compliance).converted_value\n",
    "    else:\n",
    "        spec_min = (\n",
    "            Decimal(str(spec[Spec.LIMIT][Spec.MIN]))\n",
    "            if spec[Spec.LIMIT][Spec.MIN] is not None\n",
    "            else Decimal(SpecHealth.NEGATIVE_INF)\n",
    "        )\n",
    "        spec_max = (\n",
    "            Decimal(str(spec[Spec.LIMIT][Spec.MAX]))\n",
    "            if spec[Spec.LIMIT][Spec.MAX] is not None\n",
    "            else Decimal(SpecHealth.INF)\n",
    "        )\n",
    "        min_compliance = Decimal(str(min_compliance))\n",
    "        max_compliance = Decimal(str(max_compliance))\n",
    "\n",
    "    try:\n",
    "        if spec_min is Decimal(SpecHealth.NEGATIVE_INF) and spec_max is not None:\n",
    "            return SpecHealth.PASS if max_compliance <= spec_max else SpecHealth.FAIL\n",
    "        if spec_max is Decimal(SpecHealth.INF) and spec_min is not None:\n",
    "            return SpecHealth.PASS if min_compliance <= spec_min else SpecHealth.FAIL\n",
    "        if spec_min is Decimal(SpecHealth.NEGATIVE_INF) and spec_max is Decimal(SpecHealth.INF):\n",
    "            return SpecHealth.PASS\n",
    "        if spec_min <= min_compliance <= spec_max and spec_min <= max_compliance <= spec_max:\n",
    "            return SpecHealth.PASS\n",
    "        return SpecHealth.FAIL\n",
    "    except InvalidOperation:\n",
    "        return None\n",
    "\n",
    "\n",
    "def concatenate_dataframes(\n",
    "    dfs: List[pd.DataFrame],\n",
    "    reset_index: bool = True,\n",
    "    axis: int = 1\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Concatenate multiple dataframes\n",
    "\n",
    "    Args:\n",
    "        dfs (List[pd.DataFrame]): List of dataframes\n",
    "        reset_index (bool, optional): Reset index. Defaults to True.\n",
    "        axis (int, optional): Axis to concatenate. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Returns the concatenated dataframe\n",
    "    \"\"\"\n",
    "    if reset_index:\n",
    "        for df in dfs:\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "    concatenated_df = pd.concat(dfs, axis=axis)\n",
    "\n",
    "    return concatenated_df\n",
    "\n",
    "\n",
    "def generate_spec_details_dataframe(spec: Dict) -> pd.DataFrame:\n",
    "    \"\"\"Generate spec details dataframe\n",
    "\n",
    "    Args:\n",
    "        spec (Dict): Specification data\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Spec detail dataframe\n",
    "    \"\"\"\n",
    "    spec_df = pd.DataFrame(\n",
    "        {\n",
    "            (DataframeHeaders.SPEC_DETAILS, DataframeHeaders.SPEC_ID): [spec[Spec.SPECID]],\n",
    "            (DataframeHeaders.SPEC_DETAILS, DataframeHeaders.CATEGORY): [spec[Spec.CATEGORY]],\n",
    "            (DataframeHeaders.SPEC_DETAILS, DataframeHeaders.BLOCK): [spec[Spec.BLOCK]],\n",
    "            (DataframeHeaders.SPEC_DETAILS, DataframeHeaders.SYMBOL): [spec[Spec.SYMBOL]],\n",
    "            (DataframeHeaders.SPEC_DETAILS, DataframeHeaders.NAME): [spec[Spec.NAME]],\n",
    "            (DataframeHeaders.SPEC_DETAILS, DataframeHeaders.MIN): [spec[Spec.LIMIT][Spec.MIN]],\n",
    "            (DataframeHeaders.SPEC_DETAILS, DataframeHeaders.TYPICAL): [\n",
    "                spec[Spec.LIMIT][Spec.TYPICAL]\n",
    "            ],\n",
    "            (DataframeHeaders.SPEC_DETAILS, DataframeHeaders.MAX): [spec[Spec.LIMIT][Spec.MAX]],\n",
    "            (DataframeHeaders.SPEC_DETAILS, DataframeHeaders.UNIT): [spec[Spec.UNIT]],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return spec_df\n",
    "\n",
    "\n",
    "def generate_spec_conditions_dataframe(spec_condition: Dict) -> pd.DataFrame:\n",
    "    \"\"\"Generate spec condition dataframe\n",
    "\n",
    "    Args:\n",
    "        spec_condition (Dict): Specification condition dictionary\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Spec condition dataframe\n",
    "    \"\"\"\n",
    "    condition_df = pd.DataFrame()\n",
    "\n",
    "    for condition_name, condition_data in spec_condition.items():\n",
    "        condition_header = f\"{DataframeHeaders.CONDITION} ({condition_name})\"\n",
    "        if Spec.RANGE in condition_data and len(condition_data[Spec.RANGE]) > 0:\n",
    "            condition_data = {\n",
    "                (condition_header, DataframeHeaders.MIN): [\n",
    "                    range[Spec.MIN] for range in condition_data[Spec.RANGE]\n",
    "                ],\n",
    "                (condition_header, DataframeHeaders.STEP): [\n",
    "                    range[Spec.STEP] for range in condition_data[Spec.RANGE]\n",
    "                ],\n",
    "                (condition_header, DataframeHeaders.MAX): [\n",
    "                    range[Spec.MAX] for range in condition_data[Spec.RANGE]\n",
    "                ],\n",
    "                (condition_header, DataframeHeaders.DISCRETE): [\n",
    "                    condition_data.get(Spec.DISCRETE)\n",
    "                    if len(condition_data.get(Spec.DISCRETE, [])) > 0\n",
    "                    else None\n",
    "                    for _ in condition_data[Spec.RANGE]\n",
    "                ],\n",
    "                (condition_header, DataframeHeaders.UNIT): [\n",
    "                    condition_data.get(Spec.UNIT, None) for _ in condition_data[Spec.RANGE]\n",
    "                ],\n",
    "            }\n",
    "        else:\n",
    "            condition_data = {\n",
    "                (condition_header, DataframeHeaders.MIN): [None],\n",
    "                (condition_header, DataframeHeaders.STEP): [None],\n",
    "                (condition_header, DataframeHeaders.MAX): [None],\n",
    "                (condition_header, DataframeHeaders.DISCRETE): [\n",
    "                    condition_data.get(Spec.DISCRETE)\n",
    "                    if len(condition_data.get(Spec.DISCRETE, [])) > 0\n",
    "                    else None\n",
    "                ],\n",
    "                (condition_header, DataframeHeaders.UNIT): [\n",
    "                    condition_data.get(Spec.UNIT, None)\n",
    "                ],\n",
    "            }\n",
    "        spec_condition_df = pd.DataFrame(condition_data)\n",
    "        condition_df = concatenate_dataframes([condition_df, spec_condition_df])\n",
    "\n",
    "    return condition_df\n",
    "\n",
    "\n",
    "def generate_spec_compliance_dataframe(\n",
    "    spec: Dict,\n",
    "    rows: int,\n",
    "    measurement_data: List\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Generate spec compliance dataframe\n",
    "\n",
    "    Args:\n",
    "        spec (Dict): Specification data\n",
    "        rows (int): Number of rows to append compliance data\n",
    "        measurement_data (List): Measurement data\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Spec compliance dataframe\n",
    "    \"\"\"\n",
    "    min_compliance_heading = (DataframeHeaders.COMPLIANCE, ComplianceParameters.MIN)\n",
    "    max_compliance_heading = (DataframeHeaders.COMPLIANCE, ComplianceParameters.MAX)\n",
    "    mean_compliance_heading = (DataframeHeaders.COMPLIANCE, ComplianceParameters.MEAN)\n",
    "    median_compliance_heading = (DataframeHeaders.COMPLIANCE, ComplianceParameters.MEDIAN)\n",
    "    spec_health_heading = (DataframeHeaders.COMPLIANCE, ComplianceParameters.HEALTH)\n",
    "    spec_cpk_heading = (DataframeHeaders.COMPLIANCE, ComplianceParameters.CPK)\n",
    "    spec_ck_heading = (DataframeHeaders.COMPLIANCE, ComplianceParameters.CP)\n",
    "    spec_std_heading = (DataframeHeaders.COMPLIANCE, ComplianceParameters.STANDARD_DEVIATION)\n",
    "    min_rows = max(1, rows)\n",
    "    if len(measurement_data) > 0:\n",
    "        measurement_df = pd.DataFrame({spec[Spec.SPECID]: measurement_data})\n",
    "        min_compliance = calculate_compliance(measurement_df, ComplianceParameters.MIN)\n",
    "        max_compliance = calculate_compliance(measurement_df, ComplianceParameters.MAX)\n",
    "        mean_compliance = calculate_compliance(measurement_df, ComplianceParameters.MEAN)\n",
    "        median_compliance = calculate_compliance(measurement_df, ComplianceParameters.MEDIAN)\n",
    "        spec_health = (\n",
    "            get_spec_health(spec, str(min_compliance.iloc[0]), str(max_compliance.iloc[0]))\n",
    "            if (str(min_compliance.iloc[0]) != SpecHealth.NAN and str(max_compliance.iloc[0])) != SpecHealth.NAN\n",
    "            else str()\n",
    "        )\n",
    "\n",
    "        std = Decimal(measurement_df.astype('double').std(skipna=True).iloc[0])\n",
    "\n",
    "        maxima = Decimal(max_compliance.iloc[0])\n",
    "        minima = Decimal(min_compliance.iloc[0])\n",
    "        mean = Decimal(mean_compliance.iloc[0])\n",
    "\n",
    "        is_valid_max = bool(maxima)\n",
    "        is_valid_min = bool(minima)\n",
    "        cpk_high = (\n",
    "            np.nan if not is_valid_max\n",
    "            else __calculate_cpk_high(maxima, mean, std)\n",
    "        )\n",
    "        cpk_low = (\n",
    "            np.nan if not is_valid_min \n",
    "            else __calculate_cpk_low(minima, mean, std)\n",
    "        )\n",
    "        cpk = min(cpk_high, cpk_low)\n",
    "        \n",
    "        cp = (\n",
    "            np.nan if not (is_valid_max and is_valid_min)\n",
    "            else __calculate_cp(maxima, minima, std)\n",
    "        )\n",
    "\n",
    "        compliance_data = {\n",
    "            min_compliance_heading: [min_compliance.iloc[0]] * min_rows,\n",
    "            max_compliance_heading: [max_compliance.iloc[0]] * min_rows,\n",
    "            mean_compliance_heading: [mean_compliance.iloc[0]] * min_rows,\n",
    "            median_compliance_heading: [median_compliance.iloc[0]] * min_rows,\n",
    "            spec_health_heading: [spec_health] * min_rows,\n",
    "            spec_std_heading: [std] * min_rows,\n",
    "            spec_cpk_heading: [cpk] * min_rows,\n",
    "            spec_ck_heading: [cp] * min_rows\n",
    "        }\n",
    "    else:\n",
    "        empty_compliance_data = [None] * min_rows\n",
    "        compliance_data = {\n",
    "            min_compliance_heading: empty_compliance_data,\n",
    "            max_compliance_heading: empty_compliance_data,\n",
    "            mean_compliance_heading: empty_compliance_data,\n",
    "            median_compliance_heading: empty_compliance_data,\n",
    "            spec_health_heading: empty_compliance_data,\n",
    "            spec_std_heading: empty_compliance_data,\n",
    "            spec_cpk_heading: empty_compliance_data,\n",
    "            spec_ck_heading: empty_compliance_data\n",
    "        }\n",
    "    compliance_df = pd.DataFrame(compliance_data)\n",
    "\n",
    "    return compliance_df\n",
    "\n",
    "def __calculate_cpk_high(high_limit, mean, std):\n",
    "    diff = (high_limit) - (mean)\n",
    "    if std == 0:\n",
    "        return np.inf\n",
    "    return diff / (3 * (std))\n",
    "\n",
    "def __calculate_cpk_low(low_limit, mean, std):\n",
    "    diff = (mean) - (low_limit)\n",
    "    if std == 0:\n",
    "        return np.inf\n",
    "    return diff / (3 * (std))\n",
    "\n",
    "def __calculate_cp(high_limit, low_limit, std):\n",
    "    diff = (high_limit) - (low_limit)\n",
    "    if std == 0:\n",
    "        return np.inf\n",
    "    return diff / (6 * (std))\n",
    "\n",
    "async def generate_spec_dataframe(specs: List, part_number: str) -> Dict:\n",
    "    \"\"\"Generate a spec dataframe for each spec category\n",
    "\n",
    "    Args:\n",
    "        specs (List): Specifications data\n",
    "        part_number (str): Part number of the product\n",
    "\n",
    "    Returns:\n",
    "        Dict: Dictionary of spec category and dataframe\n",
    "    \"\"\"\n",
    "    spec_data = {}\n",
    "    spec_compliance_data = {}\n",
    "\n",
    "    for spec in specs:\n",
    "        category = spec.get(Spec.CATEGORY, ApiResponse.EMPTY)\n",
    "        spec_id = spec[Spec.SPECID]\n",
    "        spec_unit = spec[Spec.UNIT]\n",
    "        spec_condition = get_spec_condition(spec)\n",
    "        spec_details_df = generate_spec_details_dataframe(spec)\n",
    "        spec_conditions_df = generate_spec_conditions_dataframe(spec_condition)\n",
    "        steps = await query_steps(part_number, spec_id)\n",
    "        measurement_data = fetch_measurement_data_for_spec(\n",
    "            steps, spec_id, spec_condition, spec_unit\n",
    "        )\n",
    "        spec_compliance_df = generate_spec_compliance_dataframe(\n",
    "            spec, len(spec_conditions_df), measurement_data\n",
    "        )\n",
    "        spec_df = concatenate_dataframes([spec_details_df, spec_conditions_df])\n",
    "\n",
    "        if category not in spec_data:\n",
    "            spec_data[category] = spec_df\n",
    "            spec_compliance_data[category] = spec_compliance_df\n",
    "        else:\n",
    "            spec_data[category] = concatenate_dataframes([spec_data[category], spec_df], False, 0)\n",
    "            spec_compliance_data[category] = concatenate_dataframes(\n",
    "                [spec_compliance_data[category], spec_compliance_df], False, 0\n",
    "            )\n",
    "\n",
    "    for category in spec_data:\n",
    "        spec_data[category] = concatenate_dataframes(\n",
    "            [spec_data[category], spec_compliance_data[category]]\n",
    "        )\n",
    "\n",
    "    return spec_data\n",
    "\n",
    "def __get_batches(list, batch_size):\n",
    "    for i in range(0, len(list), batch_size):\n",
    "        yield list[i:i+batch_size]\n",
    "\n",
    "def __format_compliance(value: Decimal) -> Decimal:\n",
    "    return '{:.4f}'.format(value)\n",
    "\n",
    "def __delete_spec_custom_property(spec, property_to_be_deleted) -> None:\n",
    "    if property_to_be_deleted in spec[Spec.PROPERTIES]:\n",
    "        del spec[Spec.PROPERTIES][property_to_be_deleted]\n",
    "\n",
    "def add_compliance_to_spec_custom_properties(specs: List, dataframe_dict: Dict) -> None:\n",
    "    specs_to_be_updated = []\n",
    "    for category, dataframe in dataframe_dict.items():\n",
    "        specIds_df = dataframe[DataframeHeaders.SPEC_DETAILS][DataframeHeaders.SPEC_ID]\n",
    "        for spec in specs:\n",
    "            spec_compliance_metrices_df = dataframe[specIds_df == spec[Spec.SPECID]][DataframeHeaders.COMPLIANCE]\n",
    "            \n",
    "            if spec_compliance_metrices_df.empty or spec_compliance_metrices_df.iloc[0].empty or (not spec_compliance_metrices_df.iloc[0][ComplianceParameters.HEALTH]):\n",
    "                __delete_spec_custom_property(spec, SpecComplianceProperties.MIN)\n",
    "                __delete_spec_custom_property(spec, SpecComplianceProperties.MAX)\n",
    "                __delete_spec_custom_property(spec, SpecComplianceProperties.MEAN)\n",
    "                __delete_spec_custom_property(spec, SpecComplianceProperties.MEDIAN)\n",
    "                __delete_spec_custom_property(spec, SpecComplianceProperties.HEALTH)\n",
    "                __delete_spec_custom_property(spec, SpecComplianceProperties.STANDARD_DEVIATION)\n",
    "                __delete_spec_custom_property(spec, SpecComplianceProperties.CPK)\n",
    "                __delete_spec_custom_property(spec, SpecComplianceProperties.CP)\n",
    "\n",
    "            else:\n",
    "                spec[Spec.PROPERTIES][SpecComplianceProperties.MIN] = str(__format_compliance(spec_compliance_metrices_df.iloc[0][ComplianceParameters.MIN]))\n",
    "                spec[Spec.PROPERTIES][SpecComplianceProperties.MAX] = str(__format_compliance(spec_compliance_metrices_df.iloc[0][ComplianceParameters.MAX]))\n",
    "                spec[Spec.PROPERTIES][SpecComplianceProperties.MEAN] = str(__format_compliance(spec_compliance_metrices_df.iloc[0][ComplianceParameters.MEAN]))\n",
    "                spec[Spec.PROPERTIES][SpecComplianceProperties.MEDIAN] = str(__format_compliance(spec_compliance_metrices_df.iloc[0][ComplianceParameters.MEDIAN]))\n",
    "                spec[Spec.PROPERTIES][SpecComplianceProperties.HEALTH] = str(spec_compliance_metrices_df.iloc[0][ComplianceParameters.HEALTH])\n",
    "                \n",
    "                spec[Spec.PROPERTIES][SpecComplianceProperties.STANDARD_DEVIATION] = str(__format_compliance(spec_compliance_metrices_df.iloc[0][ComplianceParameters.STANDARD_DEVIATION]))\n",
    "                spec[Spec.PROPERTIES][SpecComplianceProperties.CPK] = str(__format_compliance(spec_compliance_metrices_df.iloc[0][ComplianceParameters.CPK]))\n",
    "                spec[Spec.PROPERTIES][SpecComplianceProperties.CP] = str(__format_compliance(spec_compliance_metrices_df.iloc[0][ComplianceParameters.CP]))\n",
    "            \n",
    "            specs_to_be_updated.append(spec)\n",
    "\n",
    "    for specs_batch in __get_batches(specs_to_be_updated, MAX_SPECS_PER_UPDATE_REQUEST):\n",
    "        update_specs_response = update_specs(specs_batch)\n",
    "        if (update_specs_response.status_code != 200) or (\"failedSpecs\" in update_specs_response.json()):\n",
    "            sb.glue(\"Error updating spec custom properties with the compliance metrices\", json.dumps(update_specs_response.json()))\n",
    "            break\n",
    "\n",
    "def upload_file(file_name: str, workspace_id: str) -> Response:\n",
    "    \"\"\"Upload file to SLE\n",
    "\n",
    "    Args:\n",
    "        file_name (str): File name\n",
    "        part_number (str): Part number of the product\n",
    "\n",
    "    Returns:\n",
    "        Response: Upload file response\n",
    "    \"\"\"\n",
    "    upload_file_url = f\"{ApiUrls.UPLOAD_FILE_URL}?workspace={workspace_id}\"\n",
    "    file = {\"file\": (f\"{part_number}-{file_name}\", open(file_name, \"rb\"))}\n",
    "    response = upload_file_request(upload_file_url, file)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def add_file_id_to_product(product_information: Any, file_id: str) -> Response:\n",
    "    \"\"\"Add file to the product using update product API\n",
    "\n",
    "    Args:\n",
    "        product_information (Any): Product information received for get product API\n",
    "        file_id (str): File ID\n",
    "\n",
    "    Returns:\n",
    "        Response: Update product response\n",
    "    \"\"\"\n",
    "    product_information[ApiResponse.FILE_IDS].append(file_id)\n",
    "    product_information.pop(ApiResponse.UPDATED_AT)\n",
    "    body = {ApiBody.PRODUCTS: [product_information], ApiBody.REPLACE: ApiBody.FALSE}\n",
    "    response = create_post_request(ApiUrls.UPDATE_PRODUCT_URL, body)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def write_dataframe_to_excel(dataframe_dict: Dict, file_name: str) -> None:\n",
    "    \"\"\"Write each dataframe to a new sheet in excel\n",
    "\n",
    "    Args:\n",
    "        dataframe_dict (Dict): Dictionary of dataframes\n",
    "        file_name (str): File name\n",
    "    \"\"\"\n",
    "    with pd.ExcelWriter(file_name, engine=\"openpyxl\") as writer:\n",
    "        for category, dataframe in dataframe_dict.items():\n",
    "            dataframe.reset_index(drop=True, inplace=True)\n",
    "            dataframe.to_excel(writer, sheet_name=f\"Spec_{category}\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch parametric specs, measurement data, calculate Compliance and generate dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametric_specs = query_parametric_specs(product_id)\n",
    "spec_dataframe = await generate_spec_dataframe(parametric_specs, part_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write compliance metrices to custom properties of specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_compliance_to_spec_custom_properties(parametric_specs, spec_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write dataframe to excel, upload and add the excel report to the product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.float_format\", \"{:.15f}\".format)\n",
    "write_dataframe_to_excel(spec_dataframe, EXCEL_FILE_NAME)\n",
    "upload_file_response = upload_file(file_name=EXCEL_FILE_NAME, workspace_id=parametric_specs[0]['workspace']).json()\n",
    "uploaded_file_id = upload_file_response[ApiResponse.URI].split(\"/\")[-1]\n",
    "product_response = add_file_id_to_product(\n",
    "    product_information=product_information, file_id=uploaded_file_id\n",
    ").json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the result information so that SystemLink can access it\n",
    "\n",
    "SystemLink uses scrapbook to store result information from each notebook execution to display to the user in the Execution Details slide-out. Here we will display the hyperlink to files grid inside product details page or the error message incase of any error.\"\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if product_response[ApiBody.PRODUCTS]:\n",
    "        sb.glue(\n",
    "            \"Compliance excel report generated and uploaded to the product\",\n",
    "            f'<a href=\"../../testinsights/products/product/{product_id}/files\">Product Files tab</a>',\n",
    "        )\n",
    "except KeyError:\n",
    "    sb.glue(\"Error\", json.dumps(product_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "1. Publish this notebook to SystemLink by right-clicking it in the JupyterLab File Browser with the interface as Specification Analysis.\n",
    "1. Manually execute this notebook against the specs inside specs grid in product details page.\n",
    "1. Go to spec details page to view the compliance metrics generated for the specs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
