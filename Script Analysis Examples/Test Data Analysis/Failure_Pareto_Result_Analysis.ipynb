{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Failure Pareto for Test Results\n",
    "This notebook creates a failure pareto report for test results. It ties into the **Test Monitor Service** for retrieving filtered test results, the **Notebook Execution Service** for running outside of Jupyterhub, and **File Service** to store analysis result.\n",
    "\n",
    "The parameters and output use a schema recognized by the Test Monitor Reports page, which can be implemented by various report types. The Failure Pareto notebook produces data that is best shown in a pareto chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Import Python modules for executing the notebook. Pandas is used for building and handling dataframes. Scrapbook is used for recording data for the Notebook Execution Service. The SystemLink Test Monitor Client provides access to test result data for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import scrapbook as sb\n",
    "from dateutil import tz\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import systemlink.clients.nitestmonitor as testmon\n",
    "import systemlink.clients.nifile as nifile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "- `result_ids`: IDs of the test results.\n",
    "\n",
    "Parameters are also listed in the metadata for the parameters cell, along with their default values. The Notebook Execution services uses that metadata to pass parameters from the Test Monitor Reports page to this notebook. To see the metadata, select the code cell and click the wrench icon in the far left panel.\n",
    "\n",
    "Sample metadata:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"papermill\": {\n",
    "    \"parameters\": {\n",
    "      \"result_ids\": []\n",
    "    }\n",
    "  },\n",
    "  \"systemlink\": {\n",
    "    \"namespaces\": [],\n",
    "    \"parameters\": [\n",
    "      {\n",
    "        \"display_name\": \"result_ids\",\n",
    "        \"id\": \"result_ids\",\n",
    "        \"type\": \"string[]\"\n",
    "      }\n",
    "    ],\n",
    "    \"version\": 2\n",
    "  },\n",
    "  \"tags\": [\"parameters\"]\n",
    "}\n",
    "```\n",
    "\n",
    "For more information on how parameterization works, review the [papermill documentation](https://papermill.readthedocs.io/en/latest/usage-parameterize.html#how-parameters-work)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "parameters": {
      "result_ids": []
     }
    },
    "systemlink": {
     "namespaces": [
      "ni-testmanagement"
     ],
     "outputs": [],
     "parameters": [
      {
       "display_name": "result_ids",
       "id": "result_ids",
       "type": "string[]"
      }
     ],
     "version": 2
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "result_ids = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"SYSTEMLINK_API_KEY\")\n",
    "systemlink_uri = os.getenv(\"SYSTEMLINK_HTTP_URI\")\n",
    "\n",
    "class ApiUrls:\n",
    "    QUERY_PRODUCTS_URL = f\"{systemlink_uri}/nitestmonitor/v2/query-products\"\n",
    "    UPDATE_PRODUCT_URL = f\"{systemlink_uri}/nitestmonitor/v2/update-products\"\n",
    "    UPLOAD_FILE_URL = f\"{systemlink_uri}/nifile/v1/service-groups/Default/upload-files\"\n",
    "\n",
    "\n",
    "GROUP_BY = 'Part Number'\n",
    "PLOT_FILE_NAME = \"pareto_graph.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping from grouping options to Test Monitor terminology\n",
    "Translate the grouping options shown in the Test Monitor Reports page to keywords recognized by the Test Monitor API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_map = {\n",
    "    'Day': 'started_at',\n",
    "    'System': 'system_id',\n",
    "    'Test Program': 'program_name',\n",
    "    'Operator': 'operator',\n",
    "    'Part Number': 'part_number',\n",
    "    'Workspace': 'workspace'\n",
    "}\n",
    "grouping = groups_map[GROUP_BY]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Test Monitor client\n",
    "Establish a connection to SystemLink over HTTP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_api = testmon.ResultsApi()\n",
    "products_api = testmon.ProductsApi()\n",
    "files_api = nifile.FilesApi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query for results\n",
    "Query the Test Monitor Service for results matching the `results_filter` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_results_filter = \"\"\n",
    "for count, result_id in enumerate(result_ids[:-1], start = 1):\n",
    "    final_results_filter += f'Id == \"{result_id}\" or '\n",
    "\n",
    "final_results_filter += f'Id == \"{result_ids[-1]}\" '\n",
    "final_results_filter += 'and (status.statusType == \"FAILED\")'\n",
    "\n",
    "results_query = testmon.ResultsAdvancedQuery(\n",
    "    final_results_filter, order_by=testmon.ResultField.STARTED_AT\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "response = await results_api.query_results_v2(post_body=results_query)\n",
    "while response.continuation_token:\n",
    "    results = results + response.results\n",
    "    results_query.continuation_token = response.continuation_token\n",
    "    response = await results_api.query_results_v2(post_body=results_query)\n",
    "\n",
    "results_list = [result.to_dict() for result in results]\n",
    "workspace_id = results_list[0]['workspace']\n",
    "part_numbers = [result['part_number'] for result in results_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get group names\n",
    "Collect the group name for each result based on the `GROUP_BY` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = []\n",
    "for result in results_list:\n",
    "    if grouping in result:\n",
    "        group_names.append(result[grouping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pandas dataframe\n",
    "Put the data into a dataframe whose columns are test result id, status, and group name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_results = {\n",
    "    'id': [result['id'] for result in results_list],\n",
    "    'status': [result['status']['status_type'] if result['status'] else None for result in results_list],\n",
    "    grouping: group_names\n",
    "}\n",
    "\n",
    "df_results = pd.DataFrame.from_dict(formatted_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle grouping by day\n",
    "If the grouping is by day, the group name is the date and time when the test started in UTC. To group all test results from a single day together, convert to server time and remove time information from the group name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_copy = copy.copy(df_results)\n",
    "df_results_copy.fillna(value='', inplace=True)\n",
    "\n",
    "if grouping == 'started_at':\n",
    "    truncated_times = []\n",
    "    for val in df_results_copy[grouping]:\n",
    "        local_time = val.astimezone(tz.tzlocal())\n",
    "        truncated_times.append(str(datetime.date(local_time.year, local_time.month, local_time.day)))\n",
    "    df_results_copy[grouping] = truncated_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate results into groups\n",
    "Aggregate the data for each unique group and status.\n",
    "\n",
    "*See documentation for [size](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.size.html) and [unstack](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.unstack.html) here.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df_results_copy.groupby([grouping, 'status']).size().unstack(fill_value=0)\n",
    "if 'PASSED' not in df_grouped:\n",
    "    df_grouped['PASSED'] = 0\n",
    "if 'FAILED' not in df_grouped:\n",
    "    df_grouped['FAILED'] = 0\n",
    "if 'ERRORED' not in df_grouped:\n",
    "    df_grouped['ERRORED'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failure Pareto calculation\n",
    "Count the number of test failures and calculate cumulative values for the pareto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fail_count = pd.DataFrame(df_grouped['FAILED'] + df_grouped['ERRORED'])\n",
    "if grouping != 'started_at':\n",
    "    df_fail_count.sort_values(by=[0], ascending=False, inplace=True)\n",
    "total = df_fail_count[0].sum()\n",
    "pareto_values = []\n",
    "cumulative = 0\n",
    "for data_member in df_fail_count[0]:\n",
    "    cumulative += data_member\n",
    "    pareto_values.append(100 * (cumulative / total))\n",
    "\n",
    "df_pareto = df_fail_count.reset_index().set_axis([grouping, 'fail_count'], axis=1)\n",
    "df_pareto['cumulative'] = pareto_values\n",
    "\n",
    "if grouping == 'started_at':\n",
    "    df_pareto['started_at'] = pd.to_datetime(df_pareto['started_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pareto[grouping].replace(r'^$', 'No ' + GROUP_BY, regex=True, inplace=True)\n",
    "\n",
    "df_dict = {\n",
    "    'columns': pd.io.json.build_table_schema(df_pareto, index=False)['fields'],\n",
    "    'values': df_pareto.values,\n",
    "}\n",
    "\n",
    "pareto_graph = {\n",
    "    \"type\": 'data_frame',\n",
    "    'id': 'failure_pareto_results_graph',\n",
    "    'data': df_dict,\n",
    "    'config': {\n",
    "        'title': 'Failure Pareto - Results by {}'.format(GROUP_BY),\n",
    "        'graph': {\n",
    "            'axis_labels': [GROUP_BY, 'Failure Count', 'Cumulative %'],\n",
    "            'plots': [\n",
    "                {'x': grouping, 'y': 'fail_count', 'style': 'BAR', 'GROUP_BY': [grouping]},\n",
    "                {'x': grouping, 'y': 'cumulative', 'secondary_y': True, 'style': 'LINE'}\n",
    "            ],\n",
    "            'orientation': 'VERTICAL'\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate plot PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from the pareto_graph dictionary\n",
    "title = pareto_graph['config']['title']\n",
    "axis_labels = pareto_graph['config']['graph']['axis_labels']\n",
    "plots = pareto_graph['config']['graph']['plots']\n",
    "\n",
    "# Plot data\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "for plot in plots:\n",
    "    if plot['style'] == 'BAR':\n",
    "        ax1.bar(\n",
    "            df_pareto[plot['x']], \n",
    "            df_pareto[plot['y']], \n",
    "            label=plot['x'])\n",
    "        ax1.set_ylabel(axis_labels[1])\n",
    "        ax1.set_xlabel(axis_labels[0])\n",
    "    elif plot['style'] == 'LINE':\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.plot(df_pareto[plot['x']], df_pareto[plot['y']], label=plot['x'], color='r')\n",
    "        ax2.set_ylabel(axis_labels[2])\n",
    "\n",
    "# Title and legend\n",
    "plt.title(title)\n",
    "plt.legend()\n",
    "ax1.tick_params(axis='x', labelrotation = 90)\n",
    "\n",
    "# Save as PNG file\n",
    "plt.savefig(PLOT_FILE_NAME, bbox_inches='tight')\n",
    "\n",
    "# Show the plot (optional)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Plot to files service and link to products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def upload_file(file_name):\n",
    "    response = await files_api.upload(file_name)\n",
    "\n",
    "    return response\n",
    "\n",
    "async def get_products(part_numbers):\n",
    "    query_filter = \"\"\n",
    "    for part_number in part_numbers[:-1]:\n",
    "        query_filter += f'partNumber == \"{part_number}\" or '\n",
    "\n",
    "    query_filter += f'partNumber == \"{part_numbers[-1]}\"'\n",
    "    query_body = {\"filter\": query_filter}\n",
    "    response = await products_api.query_products_v2(post_body=query_body)\n",
    "\n",
    "    return response.products\n",
    "\n",
    "async def add_file_id_to_products(part_numbers, file_id):\n",
    "    products = await get_products(part_numbers)\n",
    "    for product in products:\n",
    "        product.file_ids.append(file_id)\n",
    "    body = {\"products\": products, \"replace\": False}\n",
    "    response = await products_api.update_products_v2(request_body=body)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_file_response = await upload_file(file_name=PLOT_FILE_NAME)\n",
    "uploaded_file_id = upload_file_response.uri.split(\"/\")[-1]\n",
    "product_response = await add_file_id_to_products(\n",
    "    part_numbers, file_id=uploaded_file_id\n",
    ")\n",
    "product_id = product_response.products[0].id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record results with Scrapbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.glue(\n",
    "    \"The resultant failure pareto analysis is uploaded as an image\",\n",
    "    f'<a href=\"../../testinsights/products/product/{product_id}/files\">Link to image</a>',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "1. Publish this notebook to SystemLink by right-clicking it in the JupyterLab File Browser with the interface as Test Data Analysis.\n",
    "1. Manually Analyze the results inside results grid by clicking analyze button."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
