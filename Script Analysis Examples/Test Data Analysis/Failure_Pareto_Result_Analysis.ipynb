{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Failure Pareto for Test Results\n",
    "This notebook creates a failure pareto report for test results. It ties into the **Test Monitor Service** for retrieving filtered test results, the **Notebook Execution Service** for running outside of Jupyterhub, and the **Test Monitor Reports page** at #testmonitor/reports for displaying results.\n",
    "\n",
    "The parameters and output use a schema recognized by the Test Monitor Reports page, which can be implemented by various report types. The Failure Pareto notebook produces data that is best shown in a pareto chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Import Python modules for executing the notebook. Pandas is used for building and handling dataframes. Scrapbook is used for recording data for the Notebook Execution Service. The SystemLink Test Monitor Client provides access to test result data for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import scrapbook as sb\n",
    "from dateutil import tz\n",
    "\n",
    "import systemlink.clients.nitestmonitor as testmon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "- `results_filter`: Dynamic Linq query filter for test results from the Test Monitor Service  \n",
    "  Options: Any valid Test Monitor Results Dynamic Linq filter  \n",
    "  Default: `'startedWithin <= \"30.0:0:0\"'`\n",
    "- `group_by`: The dimension along which to reduce; what each bar in the output graph represents  \n",
    "  Options: Day, System, Test Program, Operator, Part Number  \n",
    "  Default: Test Program\n",
    "\n",
    "Parameters are also listed in the metadata for the parameters cell, along with their default values. The Notebook Execution services uses that metadata to pass parameters from the Test Monitor Reports page to this notebook. Available `group_by` options are listed in the metadata as well; the Test Monitor Reports page uses these to validate inputs sent to the notebook.\n",
    "\n",
    "To see the metadata, select the code cell and click the wrench icon in the far left panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "parameters": {
      "result_ids": []
     }
    },
    "systemlink": {
     "namespaces": [
      "ni-testmanagement"
     ],
     "outputs": [],
     "parameters": [
      {
       "display_name": "result_ids",
       "id": "result_ids",
       "type": "string[]"
      }
     ],
     "version": 2
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "result_ids = []\n",
    "\n",
    "results_filter = 'startedWithin <= \"30.0:0:0\"'\n",
    "group_by = 'Part Number'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping from grouping options to Test Monitor terminology\n",
    "Translate the grouping options shown in the Test Monitor Reports page to keywords recognized by the Test Monitor API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_map = {\n",
    "    'Day': 'started_at',\n",
    "    'System': 'system_id',\n",
    "    'Test Program': 'program_name',\n",
    "    'Operator': 'operator',\n",
    "    'Part Number': 'part_number',\n",
    "    'Workspace': 'workspace'\n",
    "}\n",
    "grouping = groups_map[group_by]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Test Monitor client\n",
    "Establish a connection to SystemLink over HTTP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_api = testmon.ResultsApi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query for results\n",
    "Query the Test Monitor Service for results matching the `results_filter` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_results_filter = \"\"\n",
    "for count, result_id in enumerate(result_ids, start = 1):\n",
    "    final_results_filter += f'Id == \"{result_id}\" || '\n",
    "    \n",
    "if results_filter:\n",
    "    final_results_filter += f'(status.statusType == \"FAILED\" && {results_filter})'\n",
    "else:\n",
    "    final_results_filter = 'status.statusType == \"FAILED\"'\n",
    "results_query = testmon.ResultsAdvancedQuery(\n",
    "    final_results_filter, order_by=testmon.ResultField.STARTED_AT\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "response = await results_api.query_results_v2(post_body=results_query)\n",
    "while response.continuation_token:\n",
    "    results = results + response.results\n",
    "    results_query.continuation_token = response.continuation_token\n",
    "    response = await results_api.query_results_v2(post_body=results_query)\n",
    "\n",
    "results_list = [result.to_dict() for result in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get group names\n",
    "Collect the group name for each result based on the `group_by` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = []\n",
    "for result in results_list:\n",
    "    if grouping in result:\n",
    "        group_names.append(result[grouping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pandas dataframe\n",
    "Put the data into a dataframe whose columns are test result id, status, and group name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_results = {\n",
    "    'id': [result['id'] for result in results_list],\n",
    "    'status': [result['status']['status_type'] if result['status'] else None for result in results_list],\n",
    "    grouping: group_names\n",
    "}\n",
    "\n",
    "df_results = pd.DataFrame.from_dict(formatted_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle grouping by day\n",
    "If the grouping is by day, the group name is the date and time when the test started in UTC. To group all test results from a single day together, convert to server time and remove time information from the group name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_copy = copy.copy(df_results)\n",
    "df_results_copy.fillna(value='', inplace=True)\n",
    "\n",
    "if grouping == 'started_at':\n",
    "    truncated_times = []\n",
    "    for val in df_results_copy[grouping]:\n",
    "        local_time = val.astimezone(tz.tzlocal())\n",
    "        truncated_times.append(str(datetime.date(local_time.year, local_time.month, local_time.day)))\n",
    "    df_results_copy[grouping] = truncated_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate results into groups\n",
    "Aggregate the data for each unique group and status.\n",
    "\n",
    "*See documentation for [size](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.size.html) and [unstack](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.unstack.html) here.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df_results_copy.groupby([grouping, 'status']).size().unstack(fill_value=0)\n",
    "if 'PASSED' not in df_grouped:\n",
    "    df_grouped['PASSED'] = 0\n",
    "if 'FAILED' not in df_grouped:\n",
    "    df_grouped['FAILED'] = 0\n",
    "if 'ERRORED' not in df_grouped:\n",
    "    df_grouped['ERRORED'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failure Pareto calculation\n",
    "Count the number of test failures and calculate cumulative values for the pareto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fail_count = pd.DataFrame(df_grouped['FAILED'] + df_grouped['ERRORED'])\n",
    "if grouping != 'started_at':\n",
    "    df_fail_count.sort_values(by=[0], ascending=False, inplace=True)\n",
    "total = df_fail_count[0].sum()\n",
    "pareto_values = []\n",
    "cumulative = 0\n",
    "for data_member in df_fail_count[0]:\n",
    "    cumulative += data_member\n",
    "    pareto_values.append(100 * (cumulative / total))\n",
    "\n",
    "df_pareto = df_fail_count.reset_index().set_axis([grouping, 'fail_count'], axis=1)\n",
    "df_pareto['cumulative'] = pareto_values\n",
    "\n",
    "if grouping == 'started_at':\n",
    "    df_pareto['started_at'] = pd.to_datetime(df_pareto['started_at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the dataframe to the SystemLink reports output format\n",
    "The result format for a SystemLink report consists of a list of output objects as defined below:\n",
    "- `type`: The type of the output. Accepted values are 'data_frame' and 'scalar'.\n",
    "- `id`: Corresponds to the id specified in the 'output' metadata. Used for returning multiple outputs with the 'V2' report format.\n",
    "- `data`: A dict representing the 'data_frame' type output data.\n",
    "    - `columns`: A list of dicts containing the names and data type for each column in the dataframe.\n",
    "    - `values`: A list of lists containing the dataframe values. The sublists are ordered according to the 'columns' configuration.\n",
    "- `value`: The value returned for the 'scalar' output type.\n",
    "- `config`: The configurations for the given output.\n",
    "    - `title`: The output title.\n",
    "    - `graph`: The graph configurations.\n",
    "        - `axis_labels`: The x-axis label and y-axis label.\n",
    "        - `plots`: A list of plots to display mapped from the dataframe's columns, along with configuration options.\n",
    "            - `x`: The dataframe column corresponding to the x-axis values.\n",
    "            - `y`: The dataframe column corresponding to the y-axis values.\n",
    "            - `style`: The plot's style. Accepted values are ['LINE', 'BAR', 'SCATTER'].\n",
    "            - `color`: The plot's color. Accepted formats are ['blue', '#0000ff', 'rbg(0,0,255)'].\n",
    "            - `label`: The plot's name, to be shown in a plot legend. \n",
    "            - `secondary_y`: Whether or not to display this plot on a second y-axis.\n",
    "            - `group_by`: A list of columns in the dataframe on which to group data, e.g. to color individual points.\n",
    "        - `orientation`: 'HORIZONTAL' or 'VERTICAL'.\n",
    "        - `stacked`: Whether or not to display the plots stacked on top of each other.\n",
    "\n",
    "Here is an example of a notebook result with two outputs, one of which is a dataframe with two columns, and the other is a scalar value:\n",
    "```\n",
    "[{\n",
    "    'type': 'data_frame',\n",
    "    'id': 'output_id_1',\n",
    "    'data': {\n",
    "        'columns': [\n",
    "            {'name': 'time', 'type': 'datetime'},\n",
    "            {'name': 'value', 'type': 'number'}\n",
    "         ],\n",
    "        'values': [\n",
    "            ['2020-09-29T00:00:00.000Z', 46.1538461538],\n",
    "            ['2020-09-30T00:00:00.000Z', 63.1578947368],\n",
    "            ...\n",
    "         ]\n",
    "    },\n",
    "    'config': {\n",
    "        'title': 'My Title',\n",
    "        'graph': {\n",
    "            'axis_labels': ['X Axis', 'Y Axis'],\n",
    "            'orientation': 'VERTICAL',\n",
    "            'plots': [\n",
    "                {'x': 'time', 'y': 'value', 'style': 'BAR', 'color': '#0000ff', 'label': 'Plot 1'}\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}, {\n",
    "    'type': 'scalar',\n",
    "    'id': 'output_id_2',\n",
    "    'config': {\n",
    "        'title': 'My Title'\n",
    "    },\n",
    "    'value': 5\n",
    "}]\n",
    "```\n",
    "\n",
    "For this report, there is one output, which is a dataframe with three columns. The first column contains the group categories, which are part numbers by default. The second column contains failure counts, and the third column contains the cumulative totals as percents.\n",
    "\n",
    "| part_number | fail_count | cumulative |\n",
    "|-------------|------------|------------|\n",
    "| 151837H     | 102        | 34.459459  |\n",
    "| 154261F     | 98         | 67.567568  |\n",
    "| 193343E     | 96         | 100        |\n",
    "\n",
    "The graph configuration specifies two plots: A bar chart for the failure counts and a line chart for the cumulative percentage. We use Pandas to convert the dataframe built in the previous cells into a tabular format and then return that with the result object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pareto[grouping].replace(r'^$', 'No ' + group_by, regex=True, inplace=True)\n",
    "\n",
    "df_dict = {\n",
    "    'columns': pd.io.json.build_table_schema(df_pareto, index=False)['fields'],\n",
    "    'values': df_pareto.values,\n",
    "}\n",
    "\n",
    "pareto_graph = {\n",
    "    \"type\": 'data_frame',\n",
    "    'id': 'failure_pareto_results_graph',\n",
    "    'data': df_dict,\n",
    "    'config': {\n",
    "        'title': 'Failure Pareto - Results by {}'.format(group_by),\n",
    "        'graph': {\n",
    "            'axis_labels': [group_by, 'Failure Count', 'Cumulative %'],\n",
    "            'plots': [\n",
    "                {'x': grouping, 'y': 'fail_count', 'style': 'BAR', 'group_by': [grouping]},\n",
    "                {'x': grouping, 'y': 'cumulative', 'secondary_y': True, 'style': 'LINE'}\n",
    "            ],\n",
    "            'orientation': 'VERTICAL'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "result = [pareto_graph]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record results with Scrapbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)\n",
    "sb.glue('result', str(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
