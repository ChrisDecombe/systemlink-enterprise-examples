{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Failure Pareto for Test Results\n",
    "This notebook creates a failure pareto report for test results. It ties into the **Test Monitor Service** for retrieving filtered test results, the **Notebook Execution Service** for running outside of Jupyterhub, and the **Test Monitor Reports page** at #testmonitor/reports for displaying results.\n",
    "\n",
    "The parameters and output use a schema recognized by the Test Monitor Reports page, which can be implemented by various report types. The Failure Pareto notebook produces data that is best shown in a pareto chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Import Python modules for executing the notebook. Pandas is used for building and handling dataframes. Scrapbook is used for recording data for the Notebook Execution Service. The SystemLink Test Monitor Client provides access to test result data for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import scrapbook as sb\n",
    "from dateutil import tz\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import systemlink.clients.nitestmonitor as testmon\n",
    "\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "- `result_ids`: IDs of the test results.\n",
    "\n",
    "Parameters are also listed in the metadata for the parameters cell, along with their default values. The Notebook Execution services uses that metadata to pass parameters from the Test Monitor Reports page to this notebook. To see the metadata, select the code cell and click the wrench icon in the far left panel.\n",
    "\n",
    "Sample metadata:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"papermill\": {\n",
    "    \"parameters\": {\n",
    "      \"result_ids\": []\n",
    "    }\n",
    "  },\n",
    "  \"systemlink\": {\n",
    "    \"namespaces\": [],\n",
    "    \"parameters\": [\n",
    "      {\n",
    "        \"display_name\": \"result_ids\",\n",
    "        \"id\": \"result_ids\",\n",
    "        \"type\": \"string[]\"\n",
    "      }\n",
    "    ],\n",
    "    \"version\": 2\n",
    "  },\n",
    "  \"tags\": [\"parameters\"]\n",
    "}\n",
    "```\n",
    "\n",
    "For more information on how parameterization works, review the [papermill documentation](https://papermill.readthedocs.io/en/latest/usage-parameterize.html#how-parameters-work)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "parameters": {
      "result_ids": []
     }
    },
    "systemlink": {
     "namespaces": [
      "ni-testmanagement"
     ],
     "outputs": [],
     "parameters": [
      {
       "display_name": "result_ids",
       "id": "result_ids",
       "type": "string[]"
      }
     ],
     "version": 2
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "result_ids = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"SYSTEMLINK_API_KEY\")\n",
    "systemlink_uri = os.getenv(\"SYSTEMLINK_HTTP_URI\")\n",
    "\n",
    "class ApiUrls:\n",
    "    QUERY_PRODUCTS_URL = f\"{systemlink_uri}/nitestmonitor/v2/query-products\"\n",
    "    UPDATE_PRODUCT_URL = f\"{systemlink_uri}/nitestmonitor/v2/update-products\"\n",
    "    UPLOAD_FILE_URL = f\"{systemlink_uri}/nifile/v1/service-groups/Default/upload-files\"\n",
    "\n",
    "\n",
    "GROUP_BY = 'Part Number'\n",
    "PLOT_FILE_NAME = \"pareto_graph.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping from grouping options to Test Monitor terminology\n",
    "Translate the grouping options shown in the Test Monitor Reports page to keywords recognized by the Test Monitor API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_map = {\n",
    "    'Day': 'started_at',\n",
    "    'System': 'system_id',\n",
    "    'Test Program': 'program_name',\n",
    "    'Operator': 'operator',\n",
    "    'Part Number': 'part_number',\n",
    "    'Workspace': 'workspace'\n",
    "}\n",
    "grouping = groups_map[GROUP_BY]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Test Monitor client\n",
    "Establish a connection to SystemLink over HTTP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_api = testmon.ResultsApi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query for results\n",
    "Query the Test Monitor Service for results matching the `results_filter` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_results_filter = \"\"\n",
    "for count, result_id in enumerate(result_ids[:-1], start = 1):\n",
    "    final_results_filter += f'Id == \"{result_id}\" or '\n",
    "\n",
    "final_results_filter += f'Id == \"{result_ids[-1]}\" '\n",
    "final_results_filter += 'and (status.statusType == \"FAILED\")'\n",
    "\n",
    "results_query = testmon.ResultsAdvancedQuery(\n",
    "    final_results_filter, order_by=testmon.ResultField.STARTED_AT\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "response = await results_api.query_results_v2(post_body=results_query)\n",
    "while response.continuation_token:\n",
    "    results = results + response.results\n",
    "    results_query.continuation_token = response.continuation_token\n",
    "    response = await results_api.query_results_v2(post_body=results_query)\n",
    "\n",
    "results_list = [result.to_dict() for result in results]\n",
    "workspace_id = results_list[0]['workspace']\n",
    "part_numbers = [result['part_number'] for result in results_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get group names\n",
    "Collect the group name for each result based on the `GROUP_BY` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = []\n",
    "for result in results_list:\n",
    "    if grouping in result:\n",
    "        group_names.append(result[grouping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pandas dataframe\n",
    "Put the data into a dataframe whose columns are test result id, status, and group name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_results = {\n",
    "    'id': [result['id'] for result in results_list],\n",
    "    'status': [result['status']['status_type'] if result['status'] else None for result in results_list],\n",
    "    grouping: group_names\n",
    "}\n",
    "\n",
    "df_results = pd.DataFrame.from_dict(formatted_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle grouping by day\n",
    "If the grouping is by day, the group name is the date and time when the test started in UTC. To group all test results from a single day together, convert to server time and remove time information from the group name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_copy = copy.copy(df_results)\n",
    "df_results_copy.fillna(value='', inplace=True)\n",
    "\n",
    "if grouping == 'started_at':\n",
    "    truncated_times = []\n",
    "    for val in df_results_copy[grouping]:\n",
    "        local_time = val.astimezone(tz.tzlocal())\n",
    "        truncated_times.append(str(datetime.date(local_time.year, local_time.month, local_time.day)))\n",
    "    df_results_copy[grouping] = truncated_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate results into groups\n",
    "Aggregate the data for each unique group and status.\n",
    "\n",
    "*See documentation for [size](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.size.html) and [unstack](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.unstack.html) here.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df_results_copy.groupby([grouping, 'status']).size().unstack(fill_value=0)\n",
    "if 'PASSED' not in df_grouped:\n",
    "    df_grouped['PASSED'] = 0\n",
    "if 'FAILED' not in df_grouped:\n",
    "    df_grouped['FAILED'] = 0\n",
    "if 'ERRORED' not in df_grouped:\n",
    "    df_grouped['ERRORED'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failure Pareto calculation\n",
    "Count the number of test failures and calculate cumulative values for the pareto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fail_count = pd.DataFrame(df_grouped['FAILED'] + df_grouped['ERRORED'])\n",
    "if grouping != 'started_at':\n",
    "    df_fail_count.sort_values(by=[0], ascending=False, inplace=True)\n",
    "total = df_fail_count[0].sum()\n",
    "pareto_values = []\n",
    "cumulative = 0\n",
    "for data_member in df_fail_count[0]:\n",
    "    cumulative += data_member\n",
    "    pareto_values.append(100 * (cumulative / total))\n",
    "\n",
    "df_pareto = df_fail_count.reset_index().set_axis([grouping, 'fail_count'], axis=1)\n",
    "df_pareto['cumulative'] = pareto_values\n",
    "\n",
    "if grouping == 'started_at':\n",
    "    df_pareto['started_at'] = pd.to_datetime(df_pareto['started_at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the dataframe to the SystemLink reports output format\n",
    "The result format for a SystemLink report consists of a list of output objects as defined below:\n",
    "- `type`: The type of the output. Accepted values are 'data_frame' and 'scalar'.\n",
    "- `id`: Corresponds to the id specified in the 'output' metadata. Used for returning multiple outputs with the 'V2' report format.\n",
    "- `data`: A dict representing the 'data_frame' type output data.\n",
    "    - `columns`: A list of dicts containing the names and data type for each column in the dataframe.\n",
    "    - `values`: A list of lists containing the dataframe values. The sublists are ordered according to the 'columns' configuration.\n",
    "- `value`: The value returned for the 'scalar' output type.\n",
    "- `config`: The configurations for the given output.\n",
    "    - `title`: The output title.\n",
    "    - `graph`: The graph configurations.\n",
    "        - `axis_labels`: The x-axis label and y-axis label.\n",
    "        - `plots`: A list of plots to display mapped from the dataframe's columns, along with configuration options.\n",
    "            - `x`: The dataframe column corresponding to the x-axis values.\n",
    "            - `y`: The dataframe column corresponding to the y-axis values.\n",
    "            - `style`: The plot's style. Accepted values are ['LINE', 'BAR', 'SCATTER'].\n",
    "            - `color`: The plot's color. Accepted formats are ['blue', '#0000ff', 'rbg(0,0,255)'].\n",
    "            - `label`: The plot's name, to be shown in a plot legend. \n",
    "            - `secondary_y`: Whether or not to display this plot on a second y-axis.\n",
    "            - `GROUP_BY`: A list of columns in the dataframe on which to group data, e.g. to color individual points.\n",
    "        - `orientation`: 'HORIZONTAL' or 'VERTICAL'.\n",
    "        - `stacked`: Whether or not to display the plots stacked on top of each other.\n",
    "\n",
    "Here is an example of a notebook result with two outputs, one of which is a dataframe with two columns, and the other is a scalar value:\n",
    "```\n",
    "[{\n",
    "    'type': 'data_frame',\n",
    "    'id': 'output_id_1',\n",
    "    'data': {\n",
    "        'columns': [\n",
    "            {'name': 'time', 'type': 'datetime'},\n",
    "            {'name': 'value', 'type': 'number'}\n",
    "         ],\n",
    "        'values': [\n",
    "            ['2020-09-29T00:00:00.000Z', 46.1538461538],\n",
    "            ['2020-09-30T00:00:00.000Z', 63.1578947368],\n",
    "            ...\n",
    "         ]\n",
    "    },\n",
    "    'config': {\n",
    "        'title': 'My Title',\n",
    "        'graph': {\n",
    "            'axis_labels': ['X Axis', 'Y Axis'],\n",
    "            'orientation': 'VERTICAL',\n",
    "            'plots': [\n",
    "                {'x': 'time', 'y': 'value', 'style': 'BAR', 'color': '#0000ff', 'label': 'Plot 1'}\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}, {\n",
    "    'type': 'scalar',\n",
    "    'id': 'output_id_2',\n",
    "    'config': {\n",
    "        'title': 'My Title'\n",
    "    },\n",
    "    'value': 5\n",
    "}]\n",
    "```\n",
    "\n",
    "For this report, there is one output, which is a dataframe with three columns. The first column contains the group categories, which are part numbers by default. The second column contains failure counts, and the third column contains the cumulative totals as percents.\n",
    "\n",
    "| part_number | fail_count | cumulative |\n",
    "|-------------|------------|------------|\n",
    "| 151837H     | 102        | 34.459459  |\n",
    "| 154261F     | 98         | 67.567568  |\n",
    "| 193343E     | 96         | 100        |\n",
    "\n",
    "The graph configuration specifies two plots: A bar chart for the failure counts and a line chart for the cumulative percentage. We use Pandas to convert the dataframe built in the previous cells into a tabular format and then return that with the result object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pareto[grouping].replace(r'^$', 'No ' + GROUP_BY, regex=True, inplace=True)\n",
    "\n",
    "df_dict = {\n",
    "    'columns': pd.io.json.build_table_schema(df_pareto, index=False)['fields'],\n",
    "    'values': df_pareto.values,\n",
    "}\n",
    "\n",
    "pareto_graph = {\n",
    "    \"type\": 'data_frame',\n",
    "    'id': 'failure_pareto_results_graph',\n",
    "    'data': df_dict,\n",
    "    'config': {\n",
    "        'title': 'Failure Pareto - Results by {}'.format(GROUP_BY),\n",
    "        'graph': {\n",
    "            'axis_labels': [GROUP_BY, 'Failure Count', 'Cumulative %'],\n",
    "            'plots': [\n",
    "                {'x': grouping, 'y': 'fail_count', 'style': 'BAR', 'GROUP_BY': [grouping]},\n",
    "                {'x': grouping, 'y': 'cumulative', 'secondary_y': True, 'style': 'LINE'}\n",
    "            ],\n",
    "            'orientation': 'VERTICAL'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "result = [pareto_graph]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record results with Scrapbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.glue('result', str(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate plot PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from the pareto_graph dictionary\n",
    "title = pareto_graph['config']['title']\n",
    "axis_labels = pareto_graph['config']['graph']['axis_labels']\n",
    "plots = pareto_graph['config']['graph']['plots']\n",
    "\n",
    "# Plot data\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "for plot in plots:\n",
    "    if plot['style'] == 'BAR':\n",
    "        ax1.bar(\n",
    "            df_pareto[plot['x']], \n",
    "            df_pareto[plot['y']], \n",
    "            label=plot['x'])\n",
    "        ax1.set_ylabel(axis_labels[1])\n",
    "        ax1.set_xlabel(axis_labels[0])\n",
    "    elif plot['style'] == 'LINE':\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.plot(df_pareto[plot['x']], df_pareto[plot['y']], label=plot['x'], color='r')\n",
    "        ax2.set_ylabel(axis_labels[2])\n",
    "\n",
    "# Title and legend\n",
    "plt.title(title)\n",
    "plt.legend()\n",
    "ax1.tick_params(axis='x', labelrotation = 90)\n",
    "\n",
    "# Save as PNG file\n",
    "plt.savefig(PLOT_FILE_NAME, bbox_inches='tight')\n",
    "\n",
    "# Show the plot (optional)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Plot to files service and link to products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_post_request(url, body, headers = None):\n",
    "    \"\"\"Post request\n",
    "\n",
    "    Args:\n",
    "        url (str): API URL\n",
    "        body (_type_): Request body\n",
    "        headers (Dict, optional): API request headers. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        Response: Post request response\n",
    "    \"\"\"\n",
    "    if not headers:\n",
    "        headers = {}\n",
    "    default_headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"x-ni-api-key\": api_key,\n",
    "    }\n",
    "    headers = {**default_headers, **headers}\n",
    "\n",
    "    return requests.post(\n",
    "            url,\n",
    "            json=body,\n",
    "            headers=headers,\n",
    "            verify=False,\n",
    "        )\n",
    "\n",
    "def upload_file_request(url, file, headers=None):\n",
    "    if not headers:\n",
    "        headers = {}\n",
    "    default_headers = {\"accept\": \"application/json\", \"x-ni-api-key\": api_key}\n",
    "    headers = {**default_headers, **headers}\n",
    "\n",
    "    return requests.post(\n",
    "            url, files=file, headers=headers, verify=False\n",
    "        )\n",
    "\n",
    "def upload_file(file_name):\n",
    "    upload_file_url = f\"{ApiUrls.UPLOAD_FILE_URL}?workspace={workspace_id}\"\n",
    "    file = {\"file\": (file_name, open(file_name, \"rb\"))}\n",
    "    response = upload_file_request(upload_file_url, file)\n",
    "    response.raise_for_status()\n",
    "\n",
    "\n",
    "    return response.json()\n",
    "\n",
    "def get_products(part_numbers):\n",
    "    query_filter = \"\"\n",
    "    for part_number in part_numbers[:-1]:\n",
    "        query_filter += f'partNumber == \"{part_number}\" or '\n",
    "\n",
    "    query_filter += f'partNumber == \"{part_numbers[-1]}\"'\n",
    "    query_body = {\"filter\": query_filter}\n",
    "    response = create_post_request(ApiUrls.QUERY_PRODUCTS_URL, query_body)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    return response.json()[\"products\"]\n",
    "\n",
    "\n",
    "def add_file_id_to_products(part_numbers, file_id):\n",
    "    products = get_products(part_numbers)\n",
    "    for product in products:\n",
    "        product[\"fileIds\"].append(file_id)\n",
    "    body = {\"products\": products, \"replace\": False}\n",
    "    response = create_post_request(ApiUrls.UPDATE_PRODUCT_URL, body)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_file_response = upload_file(file_name=PLOT_FILE_NAME)\n",
    "uploaded_file_id = upload_file_response[\"uri\"].split(\"/\")[-1]\n",
    "product_response = add_file_id_to_products(\n",
    "    part_numbers, file_id=uploaded_file_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "1. Publish this notebook to SystemLink by right-clicking it in the JupyterLab File Browser with the interface as Test Data Analysis.\n",
    "1. Manually Analyze the results inside results grid by clicking analyze button."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
